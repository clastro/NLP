{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d200e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import dataloader\n",
    "from kobert_transformers import get_tokenizer\n",
    "from torch.utils.data import Dataset # 데이터로더\n",
    "import torch.nn as nn\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "from transformers import AdamW\n",
    "from transformers import BertPreTrainedModel\n",
    "from kobert_transformers import get_kobert_model, get_distilkobert_model\n",
    "from transformers import BertModel, BertConfig, GPT2Config\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbb97371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9356c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KoBERT\n",
    "kobert_config = {\n",
    "    'attention_probs_dropout_prob': 0.1,\n",
    "    'hidden_act': 'gelu',\n",
    "    'hidden_dropout_prob': 0.1,\n",
    "    'hidden_size': 768,\n",
    "    'initializer_range': 0.02,\n",
    "    'intermediate_size': 3072,\n",
    "    'max_position_embeddings': 128,\n",
    "    'num_attention_heads': 12,\n",
    "    'num_hidden_layers': 12,\n",
    "    'type_vocab_size': 2,\n",
    "    'vocab_size': 60000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e74b9a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kobert_input(tokenizer, str, device = None, max_seq_len = 128): #kobert input\n",
    "    index_of_words = tokenizer.encode(str)\n",
    "    token_type_ids = [0] * len(index_of_words)\n",
    "    attention_mask = [1] * len(index_of_words)\n",
    "\n",
    "  # Padding Length\n",
    "    padding_length = max_seq_len - len(index_of_words)\n",
    "\n",
    "  # Zero Padding\n",
    "    index_of_words += [0] * padding_length\n",
    "    token_type_ids += [0] * padding_length\n",
    "    attention_mask += [0] * padding_length\n",
    "    data = {\n",
    "        'input_ids': torch.tensor([index_of_words]).to(device),\n",
    "        'token_type_ids': torch.tensor([token_type_ids]).to(device),\n",
    "        'attention_mask': torch.tensor([attention_mask]).to(device),\n",
    "    }\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59462fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YoutubeTextClassificationDataset(Dataset): #Train DataSET\n",
    "    \"\"\"Youtube Text Classification Dataset\"\"\"\n",
    "    def __init__(self,\n",
    "               file_path = \"./data/youtube_topic_category_train_211220.csv\",\n",
    "               num_label = 18,\n",
    "               device = 'gpu',\n",
    "               max_seq_len = 128, #512 # KoBERT max_length\n",
    "               tokenizer = None\n",
    "               ):\n",
    "        self.file_path = file_path\n",
    "        self.device = device\n",
    "        self.data =[]\n",
    "        #self.tokenizer = tokenizer if tokenizer is not None else get_tokenizer()\n",
    "        self.tokenizer = get_tokenizer()\n",
    "\n",
    "        df = pd.read_csv(self.file_path, encoding='utf-8-sig')\n",
    "        df = df.sample(frac=1,random_state=0)\n",
    "\n",
    "        for title,topic_label in tqdm(zip(df['title'],df['topic_label'])):\n",
    "            index_of_words = self.tokenizer.encode(title) #title\n",
    "            token_type_ids = [0] * len(index_of_words)\n",
    "            attention_mask = [1] * len(index_of_words)\n",
    "\n",
    "            # Padding Length\n",
    "            padding_length = max_seq_len - len(index_of_words)\n",
    "            # Zero Padding\n",
    "            index_of_words += [0] * padding_length\n",
    "            token_type_ids += [0] * padding_length\n",
    "            attention_mask += [0] * padding_length\n",
    "\n",
    "\n",
    "            # Label\n",
    "            label = topic_label\n",
    "            data = {\n",
    "                  'input_ids': torch.tensor(index_of_words).to(self.device),\n",
    "                  'token_type_ids': torch.tensor(token_type_ids).to(self.device),\n",
    "                  'attention_mask': torch.tensor(attention_mask).to(self.device),\n",
    "                  'labels': torch.tensor(label).to(self.device)\n",
    "                 }    \n",
    "            self.data.append(data)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self,index):\n",
    "        item = self.data[index]\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d158982b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(device, epoch, model, optimizer, train_loader, save_step, save_ckpt_path, train_step = 0):\n",
    "    losses = []\n",
    "    train_start_index = train_step+1 if train_step != 0 else 0\n",
    "    total_train_step = len(train_loader)\n",
    "    model.train()\n",
    "\n",
    "    with tqdm(total= total_train_step, desc=f\"Train({epoch})\") as pbar:\n",
    "        pbar.update(train_step)\n",
    "        for i, data in enumerate(train_loader, train_start_index):\n",
    "\n",
    "            # data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(**data)\n",
    "\n",
    "            loss = outputs[0]\n",
    "\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            pbar.update(1)\n",
    "            pbar.set_postfix_str(f\"Loss: {loss.item():.3f} ({np.mean(losses):.3f})\")\n",
    "\n",
    "            if i >= total_train_step or i % save_step == 0:\n",
    "                torch.save({\n",
    "                    'epoch': epoch,  # 현재 학습 epoch\n",
    "                    'model_state_dict': model.state_dict(),  # 모델 저장\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),  # 옵티마이저 저장\n",
    "                    'loss': loss.item(),  # Loss 저장\n",
    "                    'train_step': i,  # 현재 진행한 학습\n",
    "                    'total_train_step': len(train_loader)  # 현재 epoch에 학습 할 총 train step\n",
    "                }, save_ckpt_path)\n",
    "\n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8b20491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentence): #Data List형태로 수정필요\n",
    "    data = kobert_input(get_tokenizer(), sentence, device, 128)\n",
    "    output = model(**data)\n",
    "    logit = output\n",
    "    softmax_logit = nn.Softmax(logit).dim\n",
    "    softmax_logit = softmax_logit[0].squeeze()\n",
    "\n",
    "    max_index = torch.argmax(softmax_logit).item()\n",
    "    max_index_value = softmax_logit[torch.argmax(softmax_logit)].item()\n",
    "\n",
    "    #answer_list = answer[category[str(max_index)]]\n",
    "    #answer_len= len(answer_list)-1\n",
    "    #answer_index = random.randint(0,answer_len)\n",
    "\n",
    "    return max_index,max_index_value,softmax_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc4ddf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kobert_config():\n",
    "    return BertConfig.from_dict(kobert_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fec5439c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KoBERTforSequenceClassfication(BertPreTrainedModel):\n",
    "    def __init__(self,\n",
    "                num_labels = 18, #분류할 토픽\n",
    "                hidden_size = 768,\n",
    "                hidden_dropout_prob = 0.1,\n",
    "               ):\n",
    "        super().__init__(get_kobert_config())\n",
    "\n",
    "        self.num_labels = num_labels\n",
    "        self.kobert = get_kobert_model()\n",
    "        self.dropout = nn.Dropout(hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(hidden_size, num_labels)\n",
    "\n",
    "        self.init_weights()\n",
    "        \n",
    "    def forward(\n",
    "          self,\n",
    "          input_ids=None,\n",
    "          attention_mask=None,\n",
    "          token_type_ids=None,\n",
    "          position_ids=None,\n",
    "          head_mask=None,\n",
    "          inputs_embeds=None,\n",
    "          labels=None,\n",
    "    ):\n",
    "    \n",
    "        outputs = self.kobert(\n",
    "          input_ids,\n",
    "          attention_mask=attention_mask,\n",
    "          token_type_ids=token_type_ids,\n",
    "          position_ids=position_ids,\n",
    "          head_mask=head_mask,\n",
    "          inputs_embeds=inputs_embeds,\n",
    "        )\n",
    "\n",
    "        pooled_output = outputs[1]\n",
    "\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        outputs = (logits,) + outputs[2:]  # add hidden states and attention if they are here\n",
    "\n",
    "        if labels is not None:\n",
    "            if self.num_labels == 1:\n",
    "                #  We are doing regression\n",
    "                loss_fct = MSELoss()\n",
    "                loss = loss_fct(logits.view(-1), labels.view(-1))\n",
    "            else:\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            outputs = (loss,) + outputs\n",
    "\n",
    "        return outputs  # (loss), logits, (hidden_states), (attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80511598",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./data/youtube_topic_category_train_211220.csv\"\n",
    "checkpoint_path =\"./checkpoint\"\n",
    "save_ckpt_path = f\"{checkpoint_path}/kobert_youtube_topic_classification_vocab_plus.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fdd99e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'KoBertTokenizer'.\n",
      "202316it [01:25, 2353.02it/s]\n"
     ]
    }
   ],
   "source": [
    "n_epoch = 50          # Num of Epoch\n",
    "batch_size = 16      # 배치 사이즈\n",
    "ctx = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(ctx)\n",
    "save_step = 500 # 학습 저장 주기\n",
    "learning_rate = 5e-6  # Learning Rate\n",
    "\n",
    "# WellnessTextClassificationDataset 데이터 로더\n",
    "dataset = YoutubeTextClassificationDataset(file_path=data_path, device=device)\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12199645",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train(0): 100%|█████████████████████████████████████████████| 12645/12645 [46:23<00:00,  4.54it/s, Loss: 0.491 (0.743)]\n",
      "Train(1): 100%|█████████████████████████████████████████████| 12645/12645 [46:30<00:00,  4.53it/s, Loss: 0.082 (0.249)]\n",
      "Train(2): 100%|█████████████████████████████████████████████| 12645/12645 [46:16<00:00,  4.55it/s, Loss: 0.141 (0.182)]\n",
      "Train(3): 100%|█████████████████████████████████████████████| 12645/12645 [46:37<00:00,  4.52it/s, Loss: 0.018 (0.145)]\n",
      "Train(4): 100%|█████████████████████████████████████████████| 12645/12645 [46:31<00:00,  4.53it/s, Loss: 0.320 (0.118)]\n",
      "Train(5): 100%|█████████████████████████████████████████████| 12645/12645 [46:30<00:00,  4.53it/s, Loss: 0.003 (0.098)]\n",
      "Train(6): 100%|█████████████████████████████████████████████| 12645/12645 [46:31<00:00,  4.53it/s, Loss: 0.263 (0.082)]\n",
      "Train(7): 100%|█████████████████████████████████████████████| 12645/12645 [46:33<00:00,  4.53it/s, Loss: 0.008 (0.069)]\n",
      "Train(8): 100%|█████████████████████████████████████████████| 12645/12645 [46:34<00:00,  4.52it/s, Loss: 0.006 (0.056)]\n",
      "Train(9): 100%|█████████████████████████████████████████████| 12645/12645 [46:50<00:00,  4.50it/s, Loss: 0.001 (0.048)]\n",
      "Train(10): 100%|████████████████████████████████████████████| 12645/12645 [46:32<00:00,  4.53it/s, Loss: 0.002 (0.040)]\n",
      "Train(11): 100%|████████████████████████████████████████████| 12645/12645 [46:33<00:00,  4.53it/s, Loss: 0.003 (0.034)]\n",
      "Train(12): 100%|████████████████████████████████████████████| 12645/12645 [46:35<00:00,  4.52it/s, Loss: 0.002 (0.030)]\n",
      "Train(13): 100%|████████████████████████████████████████████| 12645/12645 [46:34<00:00,  4.53it/s, Loss: 0.001 (0.025)]\n",
      "Train(14): 100%|████████████████████████████████████████████| 12645/12645 [46:37<00:00,  4.52it/s, Loss: 0.001 (0.023)]\n",
      "Train(15): 100%|████████████████████████████████████████████| 12645/12645 [46:40<00:00,  4.52it/s, Loss: 0.001 (0.021)]\n",
      "Train(16): 100%|████████████████████████████████████████████| 12645/12645 [46:55<00:00,  4.49it/s, Loss: 0.001 (0.017)]\n",
      "Train(17): 100%|████████████████████████████████████████████| 12645/12645 [46:33<00:00,  4.53it/s, Loss: 0.001 (0.016)]\n",
      "Train(18): 100%|████████████████████████████████████████████| 12645/12645 [46:35<00:00,  4.52it/s, Loss: 0.002 (0.015)]\n",
      "Train(19): 100%|████████████████████████████████████████████| 12645/12645 [46:34<00:00,  4.53it/s, Loss: 0.001 (0.014)]\n",
      "Train(20): 100%|████████████████████████████████████████████| 12645/12645 [46:34<00:00,  4.52it/s, Loss: 0.000 (0.013)]\n",
      "Train(21): 100%|████████████████████████████████████████████| 12645/12645 [46:33<00:00,  4.53it/s, Loss: 0.001 (0.012)]\n",
      "Train(22): 100%|████████████████████████████████████████████| 12645/12645 [46:35<00:00,  4.52it/s, Loss: 0.000 (0.011)]\n",
      "Train(23): 100%|████████████████████████████████████████████| 12645/12645 [46:34<00:00,  4.52it/s, Loss: 0.001 (0.011)]\n",
      "Train(24): 100%|████████████████████████████████████████████| 12645/12645 [46:30<00:00,  4.53it/s, Loss: 0.001 (0.010)]\n",
      "Train(25): 100%|████████████████████████████████████████████| 12645/12645 [46:28<00:00,  4.53it/s, Loss: 0.000 (0.009)]\n",
      "Train(26): 100%|████████████████████████████████████████████| 12645/12645 [46:29<00:00,  4.53it/s, Loss: 0.000 (0.008)]\n",
      "Train(27): 100%|████████████████████████████████████████████| 12645/12645 [46:31<00:00,  4.53it/s, Loss: 0.000 (0.008)]\n",
      "Train(28): 100%|████████████████████████████████████████████| 12645/12645 [46:31<00:00,  4.53it/s, Loss: 0.000 (0.008)]\n",
      "Train(29): 100%|████████████████████████████████████████████| 12645/12645 [46:34<00:00,  4.52it/s, Loss: 0.000 (0.008)]\n",
      "Train(30): 100%|████████████████████████████████████████████| 12645/12645 [46:32<00:00,  4.53it/s, Loss: 0.000 (0.007)]\n",
      "Train(31): 100%|████████████████████████████████████████████| 12645/12645 [46:34<00:00,  4.52it/s, Loss: 0.001 (0.007)]\n",
      "Train(32): 100%|████████████████████████████████████████████| 12645/12645 [46:35<00:00,  4.52it/s, Loss: 0.000 (0.007)]\n",
      "Train(33): 100%|████████████████████████████████████████████| 12645/12645 [46:38<00:00,  4.52it/s, Loss: 0.000 (0.006)]\n",
      "Train(34): 100%|████████████████████████████████████████████| 12645/12645 [47:04<00:00,  4.48it/s, Loss: 0.000 (0.006)]\n",
      "Train(35): 100%|████████████████████████████████████████████| 12645/12645 [46:34<00:00,  4.53it/s, Loss: 0.000 (0.006)]\n",
      "Train(36): 100%|████████████████████████████████████████████| 12645/12645 [46:34<00:00,  4.53it/s, Loss: 0.000 (0.006)]\n",
      "Train(37): 100%|████████████████████████████████████████████| 12645/12645 [46:36<00:00,  4.52it/s, Loss: 0.003 (0.006)]\n",
      "Train(38): 100%|████████████████████████████████████████████| 12645/12645 [46:34<00:00,  4.52it/s, Loss: 0.000 (0.006)]\n",
      "Train(39): 100%|████████████████████████████████████████████| 12645/12645 [46:33<00:00,  4.53it/s, Loss: 0.000 (0.005)]\n",
      "Train(40): 100%|████████████████████████████████████████████| 12645/12645 [46:34<00:00,  4.52it/s, Loss: 0.005 (0.005)]\n",
      "Train(41): 100%|████████████████████████████████████████████| 12645/12645 [46:29<00:00,  4.53it/s, Loss: 0.000 (0.005)]\n",
      "Train(42): 100%|████████████████████████████████████████████| 12645/12645 [46:30<00:00,  4.53it/s, Loss: 0.000 (0.005)]\n",
      "Train(43): 100%|████████████████████████████████████████████| 12645/12645 [46:29<00:00,  4.53it/s, Loss: 0.000 (0.004)]\n",
      "Train(44): 100%|████████████████████████████████████████████| 12645/12645 [46:31<00:00,  4.53it/s, Loss: 0.000 (0.004)]\n",
      "Train(45): 100%|████████████████████████████████████████████| 12645/12645 [46:35<00:00,  4.52it/s, Loss: 0.000 (0.005)]\n",
      "Train(46): 100%|████████████████████████████████████████████| 12645/12645 [46:41<00:00,  4.51it/s, Loss: 0.000 (0.004)]\n",
      "Train(47): 100%|████████████████████████████████████████████| 12645/12645 [46:38<00:00,  4.52it/s, Loss: 0.000 (0.004)]\n",
      "Train(48): 100%|████████████████████████████████████████████| 12645/12645 [46:36<00:00,  4.52it/s, Loss: 0.000 (0.004)]\n",
      "Train(49): 100%|████████████████████████████████████████████| 12645/12645 [46:34<00:00,  4.53it/s, Loss: 0.000 (0.004)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.742966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.248540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.182162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.144725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.118497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.098066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.082024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.068699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.056433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.048068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.040363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.033992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.029678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.025303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.022543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.021136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.017259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.016132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.015024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.013690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.012513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.012320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.010998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.010834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.009553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.009219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.008386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.008337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.007769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.008124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.006874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.006798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.006655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.006261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.006184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.006143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.005791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.005656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.005580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.005133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.005031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.004772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.004678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.004420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.004337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.004566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.004002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.004038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.003945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.003985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss\n",
       "0   0.742966\n",
       "1   0.248540\n",
       "2   0.182162\n",
       "3   0.144725\n",
       "4   0.118497\n",
       "5   0.098066\n",
       "6   0.082024\n",
       "7   0.068699\n",
       "8   0.056433\n",
       "9   0.048068\n",
       "10  0.040363\n",
       "11  0.033992\n",
       "12  0.029678\n",
       "13  0.025303\n",
       "14  0.022543\n",
       "15  0.021136\n",
       "16  0.017259\n",
       "17  0.016132\n",
       "18  0.015024\n",
       "19  0.013690\n",
       "20  0.012513\n",
       "21  0.012320\n",
       "22  0.010998\n",
       "23  0.010834\n",
       "24  0.009553\n",
       "25  0.009219\n",
       "26  0.008386\n",
       "27  0.008337\n",
       "28  0.007769\n",
       "29  0.008124\n",
       "30  0.006874\n",
       "31  0.006798\n",
       "32  0.006655\n",
       "33  0.006261\n",
       "34  0.006184\n",
       "35  0.006143\n",
       "36  0.005791\n",
       "37  0.005656\n",
       "38  0.005580\n",
       "39  0.005133\n",
       "40  0.005031\n",
       "41  0.004772\n",
       "42  0.004678\n",
       "43  0.004420\n",
       "44  0.004337\n",
       "45  0.004566\n",
       "46  0.004002\n",
       "47  0.004038\n",
       "48  0.003945\n",
       "49  0.003985"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = KoBERTforSequenceClassfication()\n",
    "model.to(device)\n",
    "\n",
    "# Prepare optimizer and schedule (linear warmup and decay)\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "      'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
    "\n",
    "pre_epoch, pre_loss, train_step = 0, 0, 0\n",
    "if os.path.isfile(save_ckpt_path):\n",
    "    checkpoint = torch.load(save_ckpt_path, map_location=device)\n",
    "    pre_epoch = checkpoint['epoch']\n",
    "    # pre_loss = checkpoint['loss']\n",
    "    train_step =  checkpoint['train_step']\n",
    "    total_train_step =  checkpoint['total_train_step']\n",
    "\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "    print(f\"load pretrain from: {save_ckpt_path}, epoch={pre_epoch}\")  #, loss={pre_loss}\\n\")\n",
    "    # best_epoch += 1\n",
    "\n",
    "losses = []\n",
    "offset = pre_epoch\n",
    "for step in range(n_epoch):\n",
    "    epoch = step + offset\n",
    "    loss = train(device, epoch, model, optimizer, train_loader, save_step, save_ckpt_path, train_step)\n",
    "    losses.append(loss)\n",
    "\n",
    "# data\n",
    "data = {\n",
    "    \"loss\": losses\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "display(df)\n",
    "\n",
    "# graph\n",
    "plt.figure(figsize=[12, 4])\n",
    "plt.plot(losses, label=\"loss\")\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afe60be",
   "metadata": {},
   "source": [
    "### 테스트 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271d785b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('./data/130mil_videos.csv',encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b9328f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['title'][100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a12b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(df_test['title'][100000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a7e1c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
